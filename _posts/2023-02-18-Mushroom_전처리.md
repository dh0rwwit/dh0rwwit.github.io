---
title: Mushroom_전처리
author: dh0rwwit
date: 2023-02-18 09:00:00 +0900
categories: [Applicate,Machine Learning]
tags: [ML]
render_with_liquid: false
---

2021년 12월 17일 기준으로 작성된 자료...
깃 허브로 블로그 글 쓰기 쉽지가 않네..어떻게하면 좀 예쁘게 쓸 수 있을까

1. 문제정의

- 주어진 데이터 train을 통해 식용인지 독버섯인지 구분
- DecisionT(tree 구조 모델 활용)
- 특성의 중요도 확인(특성선택;feature selection) 사용
- 주어진 데이터를 통해 모델 학습한 뒤, 독버섯인지 식용버섯인지 구분하는 문제
- train, test데이터가 따로 구분되어 있지 않다.

2. 라이브러리 호출

```
import pandas as pd
from sklearn.model_selection import train_test_split

# 트리 모델 불러오기 
from sklearn.tree import DecisionTreeClassifier
# 의사결정 트리 분류모델 : 독버섯인지 식용인지 -> 1인지 0인지로 분류
```


    2.1 분석과정
    데이터 로딩
    전체 데이터(컬럼+행+숫자)파악, 결측치 파악 -> info()
    전처리 실행 (문제와 답 분리)기술통계 -> 범주형 데이터 : 최빈값, 종류, count
    label의 비율 확인
    모델링
    교차검증 실행

3.  데이터 로딩
각 쉘마다 해당 글 입력한 뒤

```
pd.set_option('display.max_columns',None) # -1 : 맨 끝에 있는 것까지 출력해라
# 보여지는 열의 개수를 제한하지 않음

data=pd.read_csv('data/mushroom.csv')
# train과 test가 분리되어 있지 않는 csv파일
```

아래 명령어들을 각각 입력하여 데이터의 모양을 확인한다.

```
data
data.head()
data.shape
data.info()
```

> data
- 기본값은 5로 5row를 보여준다.
-  여기서 poisonus는 답(label)
- cap-shape, cap-surface, ... 는 각 버섯의 특성을 나타내는 데이로 train data들이다.
 
> data.head()
- 기본값은 5로 5row를 보여준다.
- 여기서 poisonus는 답(label)
- cap-shape, cap-surface, ... 는 각 버섯의 특성을 나타내는 데이로 train data들이다.
 
> data.shape
- 데이터 크기 확인
- 8124개의 row, 22개의 train columns + 1개의 label coulum
 
> data.info()
- 데이터가 제대로 들어가 있는지 확인
- 결측치가 없다.


4. 문제(feature=x=독립변수), 답(label=y=종속변수) 분리하기

4.1. 머신러닝과정에서 분리를 위한 라이브러리 불러오기

```
from sklearn.model_selection import train_test_split
# 문제(x) 및 답(y)으로 분리
x
y
x.shape
y.shape
data.describe() # 각 컬럼별 데이터의 개수 및 종류의 개수등이 출력된다.
y.value_counts() # 시리즈의 각 데이터 개수
```

각각 입력하여 확인해준다

5. 전처리
- 인코딩 : 컴퓨터가 기계학습이 가능하도록 문자열 데이터를 수치형 데이터로 변환하는 것
- label 데이터는 순서가 있는 데이터, 순서가 없는데이터 다 변환이 가능하다
- 순서가 없는 데이터 인코딩에 사용하는 방식은 one_hot Encoding
 
5.1 인코딩 = 원핫인코딩 + 라벨 인코딩
- 원핫 인코딩 : 값의 크기가 크든 작든 의미가 없을 경우 사용 - 0과 1
- 라벨 인코딩 : 1,2,3, ... 으로 인코딩하는 것, 순서의 성질을 가지고 있는 데이터의 인코딩에 사용(1등급, 2등급, 3등급)


```
# 원핫 인코딩
x_one_hot=pd.get_dummies(x)
x_one_hot.head()

# 라벨 인코딩, 먼저 컬럼하나 성분보기
x['habitat']
# 컬럼 하나 데이터 종류 보기
x['habitat'].unique()

# 알파벳들을 숫자로 정의해준다.
dic={
    'u':0,
    'g':3,
    'm':2,
    'd':1,
    'p':4,
    'w':6,
    'l':5
}
x['habitat'].map(dic)
```

6. 모델링
- train데이터량 : test데이터량 = 7:3
- train_test_split : 랜덤 샘플링하는 것

```
- csv하나에 train, test데이터가 다 들어있을 경우 시행
from sklearn.model_selection import train_test_split

x_train, x_test, y_train, y_test =  train_test_split(x_one_hot, 
                                                     y, 
                                                     test_size=0.3, 
                                                     random_state=7)
# 이제 x_test, y_test는 모델의 train에 관여하는 데이터는 아니다
# -> x_train과 y_train 데이터로 모델 학습시킨 뒤에
# -> 학습한 모델에 x_test를 집어넣고, y_test와 얼마나 맞는지를 평가하는 역할을 한다

# 모델객체생성
tree_model=DecisionTreeClassifier()
```

6.3. 교차검증
- 개념 : 일반화 성능 측정 방법
    > train, test를 한번 나누는 것보다 더 안정적인 통계적 평가라고 한다.
- 방법론 : train, test 세트로 여러겹 나눠 평가
- 사용 : 모델을 정의하고 학습하기 전에 정확도가 어느 정도 일치하는지 확인할 때 사용한다

```
from sklearn.model_selection import cross_val_score # 과대 적합 제어 도구

cross_val_score(tree_model, x_train, y_train, cv=5) # cv는 교차검증 횟수
# 테스트 데이터의 비율에 따라 데이터의 민감도를 측정한다
```

6.4, 70% 데이터들로 tree model 학습

```
# 70%로 나눠진 데이터들로 생성된 모델을 학습
tree_model.fit(x_train, y_train) # 해당과정 시간이 많이 걸림...
```

6.5 tree model 테스트하기
- 학습한 모델의 정확도를 확인하는 과정
 
실제 문제라 가정한 x_test를 모델에 대입하여 예측답안을

```
tree_model.predict(x_test)
```

변수 pre에 저장하고

```
# 학습시킨 모델에 실제 값이라 가정된 x_test 데이터들을 대입. 
pre=tree_model.predict(x_test)

from sklearn.metrics import accuracy_score as accs
```

해당 변수 pre를 실제답안이라 가정한 y_test와 비교하며 확인한다.

```
# 정확도 확인
accs(pre, y_test)
# 결과는 1.0으로 과대적합이 나왔었다.
```

6.6 과대적합 제어

```
# 과대적합 제어
tree_model2=DecisionTreeClassifier(max_depth=3)

# 과대 적합 제어 후 모델의 일반화 성능 확인
cross_val_score(tree_model2, x_train, y_train, cv=5)
# 5번 모델을 테스트해봐도 교차검증 정확도에 큰 차이가 없었다.
# 그러므로 이 모델은 일반화가 된 모델일 가능성이 높다
```

7. 특성 중요도확인

```
ip = tree_model.feature_importances_
ip

# df로 만들어서 편하게 보기
ip_df = pd.DataFrame(ip, index = x_one_hot.columns)
ip_df

ip_df.sort_values

ip_df.sort_values(by = 0, ascending=False) [:10] 

# 괄호안에 shift+tab하면 안에 넣을 수 있는 변수 볼 수 있다.
# ascending의 디폴트값은 True로 오름차순이다.

ip_df.sort_values(by = 0, ascending=False).tail(10)
```

